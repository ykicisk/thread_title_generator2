{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_encoder import NanJThreadTitleEncoder\n",
    "text_encoder = NanJThreadTitleEncoder.load_from_file(\"../model/text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/input.pickle\", \"rb\") as f:\n",
    "    ids = pickle.load(f)\n",
    "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(ids, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "vocab_size = text_encoder.vocab_size()\n",
    "embedding_dim = 128\n",
    "gen_units = 128\n",
    "gru_units = 128\n",
    "num_stacks = 4\n",
    "seq_len = input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import create_rnn_generator_model, create_generation_evaluator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_epoch = 16\n",
    "generator = create_rnn_generator_model(gen_units, embedding_dim, vocab_size, num_stacks)\n",
    "generator.load_weights(f'../model/rnn_generator/weights_epoch{generator_epoch}.h5')\n",
    "generator.trainable = False\n",
    "\n",
    "embedding_layer = generator.get_layer(name=\"embedding\")\n",
    "embedding_layer.trainable = False\n",
    "\n",
    "evaluator_epoch = 10\n",
    "evaluator = create_generation_evaluator_model(embedding_layer, gru_units, embedding_dim, seq_len, vocab_size)\n",
    "evaluator.load_weights(f'../model/evaluator/weights_epoch{evaluator_epoch}.h5')\n",
    "evaluator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 128)       2560512     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       [(None, 1, 128), (No 99072       embedding[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 1, 128), (No 99072       gru[0][0]                        \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, 1, 128), (No 99072       gru_1[0][0]                      \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     [(None, 128), (None, 99072       gru_2[0][0]                      \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20004)        2580516     gru_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 5,537,316\n",
      "Trainable params: 0\n",
      "Non-trainable params: 5,537,316\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 24, 128)           2560512   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 24, 256)           198144    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,088,641\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,088,641\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "evaluator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(num_generations, prefix=None):\n",
    "    \"\"\"\n",
    "    Generatorを使ってnum_generations個の文書（トークンID列）を生成する\n",
    "    prefixにトークンID列を指定することで、特定のPrefixのスレタイを生成する\n",
    "    \"\"\"\n",
    "    gen_states = []\n",
    "    for _ in range(num_stacks):\n",
    "        gen_states.append(tf.zeros((num_generations, gru_units)))\n",
    "    \n",
    "    gen_input = tf.expand_dims([text_encoder.SOS_TOKEN_ID] * num_generations, 1)\n",
    "    generation_ids_list = [gen_input]\n",
    "    if prefix is not None:\n",
    "        for t in prefix:\n",
    "            gen_input = generation_ids_list[-1]\n",
    "            gen_output = generator([gen_input] + gen_states)\n",
    "            gen_states = gen_output[1:]\n",
    "            # generation_ids_listをprefixで埋める\n",
    "            generation_ids_list.append(tf.expand_dims([t] * num_generations, 1))     \n",
    "        \n",
    "    for i in range(seq_len - len(generation_ids_list)):\n",
    "        gen_input = generation_ids_list[-1]\n",
    "        gen_output = generator([gen_input] + gen_states)\n",
    "        predictions = gen_output[0]\n",
    "        gen_states = gen_output[1:]\n",
    "        next_ids = tf.random.categorical(predictions, num_samples=1, dtype=\"int32\")\n",
    "        generation_ids_list.append(next_ids)\n",
    "    generation_ids = tf.concat(generation_ids_list, axis=1)\n",
    "    return generation_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluatorあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = generate(5000).numpy()\n",
    "scores = evaluator(predicted_ids).numpy().flatten()\n",
    "for ids, s in sorted(zip(predicted_ids, scores), key=lambda x: -x[1])[:20]:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)), \"score:\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = text_encoder.encode([\"三大\"])\n",
    "predicted_ids = generate(5000, prefix=prefix).numpy()\n",
    "scores = evaluator(predicted_ids).numpy().flatten()\n",
    "for ids, s in sorted(zip(predicted_ids, scores), key=lambda x: -x[1])[:20]:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)), \"score:\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = text_encoder.encode([\"【\", \"なぞなぞ\", \"】\"])\n",
    "predicted_ids = generate(5000, prefix=prefix).numpy()\n",
    "scores = evaluator(predicted_ids).numpy().flatten()\n",
    "for ids, s in sorted(zip(predicted_ids, scores), key=lambda x: -x[1])[:20]:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)), \"score:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluatorなし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = generate(20).numpy()\n",
    "for ids in predicted_ids:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = text_encoder.encode([\"三大\"])\n",
    "predicted_ids = generate(20, prefix=prefix).numpy()\n",
    "for ids in predicted_ids:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation\n",
    "prefix = text_encoder.encode([\"【\", \"なぞなぞ\", \"】\"])\n",
    "predicted_ids = generate(20, prefix=prefix).numpy()\n",
    "for ids in predicted_ids:\n",
    "    print(\"Generation:\", \" \".join(text_encoder.decode(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
